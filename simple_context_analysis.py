#!/usr/bin/env python3
"""
Simple analysis of 130k token context window sufficiency
"""

def analyze_130k_context():
    print("130k TOKEN CONTEXT WINDOW ANALYSIS")
    print("=" * 40)
    
    # Token conversion
    print(f"\nToken Conversions:")
    print(f"130k tokens â‰ˆ 520k English characters")
    print(f"130k tokens â‰ˆ 260k Chinese characters")
    
    # Realistic scenario breakdown
    chat_history = 30 * 150  # 30 messages average 150 tokens
    documents = 5 * 2000     # 5 documents at 2000 tokens each  
    instructions = 1000      # Comprehensive instructions
    functions = 8 * 150       # 8 function definitions
    examples = 2000         # Code examples
    
    total = chat_history + documents + instructions + functions + examples
    remaining = 130000 - total
    percent_used = (total / 130000) * 100
    
    print(f"\nYour Scenario Breakdown:")
    print(f"Chat History (30 msgs):  {chat_history:,} tokens")
    print(f"Documents (5 x 2k):     {documents:,} tokens")
    print(f"Instructions:            {instructions:,} tokens")
    print(f"Functions (8 x 150):    {functions:,} tokens")
    print(f"Examples:                {examples:,} tokens")
    print(f"")
    print(f"TOTAL USED:             {total:,} tokens ({percent_used:.1f}%)")
    print(f"REMAINING:               {remaining:,} tokens")
    
    # Analysis
    print(f"\nAnalysis:")
    if percent_used < 60:
        status = "EXCELLENT"
        verdict = "Plenty of room for additional content"
    elif percent_used < 80:
        status = "GOOD"
        verdict = "Well-balanced usage"
    elif percent_used < 95:
        status = "ADEQUATE"
        verdict = "Getting tight, monitor usage"
    else:
        status = "TIGHT"
        verdict = "May need optimization"
    
    print(f"Status: {status}")
    print(f"Verdict: {verdict}")
    
    # Key insights
    print(f"\nKey Insights:")
    
    print(f"\nâœ… 130k is GENERALLY SUFFICIENT because:")
    print(f"   â€¢ Typical chat: 20-50 messages use 3k-7k tokens")
    print(f"   â€¢ Documents: 5-10 PDF/docs use 10k-20k tokens each")
    print(f"   â€¢ Instructions: Prompts use 0.5k-2k tokens")
    print(f"   â€¢ Most scenarios fit comfortably under 50k-80k tokens")
    
    print(f"\nâš ï¸  Challenges when FULL:")
    print(f"   â€¢ Very long chat histories (100+ messages)")
    print(f"   â€¢ Multiple comprehensive documents")
    print(f"   â€¢ Large codebase with many files")
    print(f"   â€¢ Extensive function calling")
    
    print(f"\nðŸ’¡ Optimization Strategies:")
    print(f"   â€¢ Smart chunking - include only relevant content")
    print(f"   â€¢ Conversation summarization - reduce history")
    print(f"   â€¢ Sliding window - keep recent context")
    print(f"   â€¢ Vector search - find most relevant content")
    print(f"   â€¢ Progressive disclosure - expand as needed")
    
    print(f"\nðŸŽ¯ For Your Use Case:")
    if percent_used < 80:
        print(f"130k window fits your requirements well!")
        print(f"You have adequate buffer for edge cases and expansion.")
    else:
        print(f"130k will work but requires smart management.")
        print(f"Implement content optimization strategies above.")
    
    # Practical examples
    print(f"\nPractical Examples:")
    print(f"âœ… Enterprise auth system docs: Fits easily (~15k tokens)")
    print(f"âœ… API documentation (10 pages): Fits (~20k tokens)")
    print(f"âœ… Medium codebase analysis: Fits (~40k tokens)")
    print(f"âš ï¸  Large enterprise system: Tight (~80-100k tokens)")
    print(f"âš ï¸  Multiple project docs: May exceed (~120k+ tokens)")
    
    return percent_used < 95

def main():
    print("CONTEXT WINDOW SUFFICIENCY CHECK")
    
    try:
        adequate = analyze_130k_context()
        
        print(f"\n" + "=" * 40)
        print("CONCLUSION:")
        print("=" * 40)
        
        if adequate:
            print("130k is ADEQUATE for most enterprise scenarios")
            print("Smart management required for complex cases")
        else:
            print("130k is TIGHT for complex scenarios")
            print("Consider optimization or larger context models")
        
        print(f"Key: The 130k limit is generous but NOT unlimited")
        print(f"Most applications work well with smart content selection")
        
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
